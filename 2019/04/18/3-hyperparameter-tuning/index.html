<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Tuning processHow to systematically organize your hyperparameter tuning process One of the painful things about training deepness :  the sheer number of hyperparameters Momentum the number of layers t">
<meta property="og:type" content="article">
<meta property="og:title" content="3 Hyperparameter tuning">
<meta property="og:url" content="http://example.com/2019/04/18/3-hyperparameter-tuning/index.html">
<meta property="og:site_name" content="Water&#39;s Home">
<meta property="og:description" content="Tuning processHow to systematically organize your hyperparameter tuning process One of the painful things about training deepness :  the sheer number of hyperparameters Momentum the number of layers t">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-04-18T01:37:59.000Z">
<meta property="article:modified_time" content="2022-07-04T07:26:09.544Z">
<meta property="article:author" content="Water">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2019/04/18/3-hyperparameter-tuning/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>3 Hyperparameter tuning | Water's Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Water's Home</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Just another Life Style</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/04/18/3-hyperparameter-tuning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Water">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Water's Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          3 Hyperparameter tuning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-04-18 09:37:59" itemprop="dateCreated datePublished" datetime="2019-04-18T09:37:59+08:00">2019-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-04 15:26:09" itemprop="dateModified" datetime="2022-07-04T15:26:09+08:00">2022-07-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine-learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep-learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/Deep-Learning-Specialization-Offered-By-deeplearning-ai/" itemprop="url" rel="index"><span itemprop="name">Deep Learning Specialization Offered By deeplearning.ai</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Tuning-process"><a href="#Tuning-process" class="headerlink" title="Tuning process"></a>Tuning process</h2><p>How to systematically organize your hyperparameter tuning process One of the painful things about training deepness :</p>
<ul>
<li>the sheer number of hyperparameters</li>
<li><strong>Momentum</strong></li>
<li>the number of layers</li>
<li>the number of <strong>hidden units</strong> for the different layers</li>
<li><strong>learning rate</strong> decay</li>
<li><strong>mini-batch</strong> size</li>
</ul>
<p>How do you select a set of values to explore</p>
<ul>
<li>It was common practice to sample the points in a grid and systematically explore these values.</li>
<li>In deep learning, what we tend to do, is choose the points at random.</li>
<li>Another common practice is to use a coarse to fine sampling scheme.<ul>
<li>zoom in to a smaller region of the hyperparameters and then sample more density within this space </li>
<li>use random sampling and adequate search</li>
</ul>
</li>
</ul>
<h2 id="Using-an-appropriate-scale-to-pick-hyperparameters"><a href="#Using-an-appropriate-scale-to-pick-hyperparameters" class="headerlink" title="Using an appropriate scale to pick hyperparameters"></a>Using an appropriate scale to pick hyperparameters</h2><p>It’s important to pick the <strong>appropriate scale</strong> on which to explore the hyperparamaters.</p>
<ul>
<li>uniformly at random</li>
<li>log scale</li>
</ul>
<h2 id="Pandas-VS-Caviar（Hyperparameters-tuning-in-practice-Pandas-vs-Caviar）"><a href="#Pandas-VS-Caviar（Hyperparameters-tuning-in-practice-Pandas-vs-Caviar）" class="headerlink" title="Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）"></a>Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）</h2><p>Deep learning today is applied to many different application areas and that intuitions about hyperparameter settings from one application area may or may not transfer to a different one. People from different application domains do read increasingly research papers from other application domains to look for inspiration for cross-fertilization. How to search for good hyperparameters : <strong>the panda approach</strong> versus <strong>the caviar approach</strong></p>
<h2 id="Normalizing-activations-in-a-network"><a href="#Normalizing-activations-in-a-network" class="headerlink" title="Normalizing activations in a network"></a>Normalizing activations in a network</h2><p>Batch normalization makes your hyperparameter search problem much easier, makes the neural network much more robust to the choice of hyperparameters, there’s a much bigger range of hyperparameters that work well, and will also enable you to much more easily train even very deep networks.</p>
<h2 id="Fitting-Batch-Norm-into-a-neural-network"><a href="#Fitting-Batch-Norm-into-a-neural-network" class="headerlink" title="Fitting Batch Norm into a neural network"></a>Fitting Batch Norm into a neural network</h2><p>The Programming framework which will make using Batch Norm much easier.</p>
<h2 id="Why-does-Batch-Norm-work？"><a href="#Why-does-Batch-Norm-work？" class="headerlink" title="Why does Batch Norm work？"></a>Why does Batch Norm work？</h2><ul>
<li>normalizing all the features to take on a similar range of values that can speed up learning</li>
<li>makes weights,later or deeper than your network</li>
<li>It reduces the amount that the distribution of these hidden unit values shifts around.</li>
<li>Batch norm reduces the problem of the input values changing, it really causes these values to become more stable, so that the later layers of the neural network has more firm ground to stand on.</li>
<li>It weakens the coupling between what the early layers parameters has to do and what the later layers parameters have to do. And so it allows each layer of the network to learn by itself, a little bit more independently of other layers, and this has the effect of speeding up learning in the whole network.</li>
<li>Batch norm therefore has a slight regularization effect. Because by adding noise to the hidden units, it’s forcing the downstream hidden units not to rely too much on any one hidden unit.</li>
</ul>
<h2 id="Batch-Norm-at-test-time"><a href="#Batch-Norm-at-test-time" class="headerlink" title="Batch Norm at test time"></a>Batch Norm at test time</h2><p>Batch norm processes your data one mini batch at a time, but the test time you might need to process the examples one at a time. So the takeaway from this is that during training time [latex]\mu[&#x2F;latex] and [latex]\sigma ^2[&#x2F;latex] are computed on an entire mini batch of, say, 64, 28 or some number of examples. But at test time, you might need to process a single example at a time. So, the way to do that is to estimate [latex]\mu[&#x2F;latex] and [latex]\sigma ^2[&#x2F;latex] from your training set and there are many ways to do that. But in practice, what people usually do is implement an exponentially weighted average where you just keep track of the [latex]\mu[&#x2F;latex] and [latex]\sigma ^2[&#x2F;latex] values you’re seeing during training and use an exponentially weighted average, also sometimes called the running average, to just get a rough estimate of [latex]\mu[&#x2F;latex] and [latex]\sigma ^2[&#x2F;latex] and then you use those values of [latex]\mu[&#x2F;latex] and [latex]\sigma ^2[&#x2F;latex] at test time to do the scaling you need of the hidden unit values Z. Deep learning framework usually have some default way to estimate the [latex]\mu[&#x2F;latex] and [latex]\sigma ^2[&#x2F;latex] that should work reasonably well as well.</p>
<h2 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h2><p>Softmax regression that lets you make predictions where you’re trying to recognize one of C or one of multiple classes, rather than just recognize two classes.</p>
<h2 id="Training-a-Softmax-classifier"><a href="#Training-a-Softmax-classifier" class="headerlink" title="Training a Softmax classifier"></a>Training a Softmax classifier</h2><p>Loss Function in softmax classification : [latex]L(\hat y, y) &#x3D; -\sum _{j&#x3D;1}^{j}y_{j}log(\hat y_{j})[&#x2F;latex] It looks at whatever is the ground truth class in your training set, and it tries to make the corresponding probability of that class as high as possible. If you’re familiar with maximum likelihood estimation statistics, this turns out to be a form of maximum likelyhood estimation. The cost J on the entire training set : [latex]J(w^{[1]}, b^{[1]}, \cdots \cdots ) &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{m} L(\hat y ^{(i)}, y ^{(i)})[&#x2F;latex] Usually it turns out you just need to focus on getting the forward prop right. And so long as you specify it as a program framework, the forward prop pass, the program framework will figure out how to do back prop, how to do the backward pass for you.</p>
<h2 id="Deep-Learning-frameworks"><a href="#Deep-Learning-frameworks" class="headerlink" title="Deep Learning frameworks"></a>Deep Learning frameworks</h2><p>At least for most people, is not practical to implement everything yourself from scratch. Fortunately, there are now many good deep learning software frameworks that can help you implement these models. <strong>choose frameworks :</strong></p>
<ul>
<li><strong>Ease of programming</strong></li>
<li><strong>Running speed</strong></li>
<li><strong>Truly open</strong></li>
<li>Preferences of language</li>
<li>What application you’re working on</li>
</ul>
<h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><h4 id="Example"><a href="#Example" class="headerlink" title="Example :"></a>Example :</h4><p>import numpy as np<br>import tensorflow as tf</p>
<p>w&#x3D;tf.Variable(0,dtype&#x3D;tf.float32)<br>#cost&#x3D;tf.add(tf.add(w**2,tf.multiply(-10,w)),25)<br>cost&#x3D;w**2-10*w+25<br>train&#x3D;tf.train.GradientDescentOptimizer(0.01).minimize(cost)</p>
<p>init&#x3D;tf.global_variables_initializer()<br>session&#x3D;tf.Session()<br>session.run(init)<br>print(session.run(w))<br>#0.0</p>
<p>session.run(train)<br>print(session.run(w))<br>#0.1</p>
<p>for i in range(1000):<br>    session.run(train)<br>print(session.run(w))<br>#4.99999</p>
<h4 id="Example-placeholder"><a href="#Example-placeholder" class="headerlink" title="Example (placeholder):"></a>Example (placeholder):</h4><p>coefficients&#x3D;np.array([[1.],[-10.],[25.]])</p>
<p>w&#x3D;tf.Variable(0,dtype&#x3D;tf.float32)<br>x&#x3D;tf.placeholder(tf.float32,[3,1])</p>
<p>cost&#x3D;x[0][0]*w**2+x[1][0]*w+x[2][0]<br>train&#x3D;tf.train.GradientDescentOptimizer(0.01).minimize(cost)</p>
<p>init&#x3D;tf.global_variables_initializer()<br>session&#x3D;tf.Session()<br>session.run(init)<br>print(session.run(w))<br>#0.0</p>
<p>session.run(train,feed_dict&#x3D;{x:coefficients})<br>print(session.run(w))<br>#0.1</p>
<p>for i in range(1000):<br>    session.run(train,feed_dict&#x3D;{x:coefficients})<br>print(session.run(w))<br>#4.99999</p>
<p><strong>the TensorFlow documentation tends to just write the operation.</strong></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/04/17/2-optimization-algorithms/" rel="prev" title="2 Optimization algorithms">
      <i class="fa fa-chevron-left"></i> 2 Optimization algorithms
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/04/18/1-ml-strategy-1/" rel="next" title="1 ML strategy (1)">
      1 ML strategy (1) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tuning-process"><span class="nav-number">1.</span> <span class="nav-text">Tuning process</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Using-an-appropriate-scale-to-pick-hyperparameters"><span class="nav-number">2.</span> <span class="nav-text">Using an appropriate scale to pick hyperparameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pandas-VS-Caviar%EF%BC%88Hyperparameters-tuning-in-practice-Pandas-vs-Caviar%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Normalizing-activations-in-a-network"><span class="nav-number">4.</span> <span class="nav-text">Normalizing activations in a network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fitting-Batch-Norm-into-a-neural-network"><span class="nav-number">5.</span> <span class="nav-text">Fitting Batch Norm into a neural network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Why-does-Batch-Norm-work%EF%BC%9F"><span class="nav-number">6.</span> <span class="nav-text">Why does Batch Norm work？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Batch-Norm-at-test-time"><span class="nav-number">7.</span> <span class="nav-text">Batch Norm at test time</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Softmax-regression"><span class="nav-number">8.</span> <span class="nav-text">Softmax regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-a-Softmax-classifier"><span class="nav-number">9.</span> <span class="nav-text">Training a Softmax classifier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Learning-frameworks"><span class="nav-number">10.</span> <span class="nav-text">Deep Learning frameworks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow"><span class="nav-number">11.</span> <span class="nav-text">TensorFlow</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Example"><span class="nav-number">11.0.1.</span> <span class="nav-text">Example :</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Example-placeholder"><span class="nav-number">11.0.2.</span> <span class="nav-text">Example (placeholder):</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Water"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Water</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">216</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/linmonsv" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;linmonsv" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qin2@qq.com" title="E-Mail → mailto:qin2@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Water</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
