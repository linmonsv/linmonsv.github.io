<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Optimization ObjectiveWithin supervised learning, the performance of many supervised learning algorithms will be pretty similar and when that is less more often be whether you use learning algorithm A">
<meta property="og:type" content="article">
<meta property="og:title" content="12 Support Vector Machines">
<meta property="og:url" content="http://example.com/2019/04/02/12-support-vector-machines/index.html">
<meta property="og:site_name" content="Water&#39;s Home">
<meta property="og:description" content="Optimization ObjectiveWithin supervised learning, the performance of many supervised learning algorithms will be pretty similar and when that is less more often be whether you use learning algorithm A">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-04-02T08:07:38.000Z">
<meta property="article:modified_time" content="2022-07-04T07:26:09.502Z">
<meta property="article:author" content="Water">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2019/04/02/12-support-vector-machines/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>12 Support Vector Machines | Water's Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Water's Home</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Just another Life Style</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/04/02/12-support-vector-machines/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Water">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Water's Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          12 Support Vector Machines
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-04-02 16:07:38" itemprop="dateCreated datePublished" datetime="2019-04-02T16:07:38+08:00">2019-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-04 15:26:09" itemprop="dateModified" datetime="2022-07-04T15:26:09+08:00">2022-07-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine-learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/" itemprop="url" rel="index"><span itemprop="name">Machine Learning Offered By Stanford University</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Optimization-Objective"><a href="#Optimization-Objective" class="headerlink" title="Optimization Objective"></a>Optimization Objective</h2><p><strong>Within supervised learning, the performance of many supervised learning algorithms will be pretty similar</strong> and when that is less more often be whether you use learning algorithm A or learning algorithm B but when that is small there will often be things like the amount of data you are creating these algorithms on. That’s always <strong>your skill in applying this algorithms</strong>. Seems like your <strong>choice of the features</strong> that you designed to give the learning algorithms and how you choose the <strong>regularization parameter</strong> and things like that. <strong>Support Vector Machine</strong> (<strong>SVM</strong>) : sometimes gives a cleaner and sometimes more powerful way of learning complex nonlinear functions. <strong>Alternative view of logistic regression</strong> [latex]h_\theta (x) &#x3D; \frac {1}{1 + e^{-\theta ^{T}x}}[&#x2F;latex]   Cost of example :  [latex]-(ylogh_\theta (x) + (1-y)log(1-h_\theta(x))) [&#x2F;latex]   [latex]&#x3D; -ylog\frac {1}{1 + e^{-\theta ^{T}x}} + (1-y)log(1-\frac {1}{1 + e^{-\theta ^{T}x}})[&#x2F;latex]   <strong>Support vector machine</strong> Logistic regression :  [latex]\underset{\theta }{min} \frac{1}{m} [\sum_{i&#x3D;1}^{m}y^{(i)}(-logh_\theta(x^{(i)})) + (1-y^{(i)})(-log(1-h_\theta (x^{(i)})))] + \frac{\lambda }{2m}\sum_{j&#x3D;1}^{n} \theta _j^2[&#x2F;latex]   Support vector machine :  [latex]\underset{\theta }{min} C [\sum_{i&#x3D;1}^{m}y^{(i)}cost_1(\theta ^Tx^{(i)}) + (1-y^{(i)})cost_0(\theta ^Tx^{(i)})] + \frac{1}{2}\sum_{i&#x3D;1}^{n} \theta _j^2[&#x2F;latex]  </p>
<h2 id="Large-Margin-Intuition"><a href="#Large-Margin-Intuition" class="headerlink" title="Large Margin Intuition"></a>Large Margin Intuition</h2><p>Sometimes people talk about support vector machines, as <strong>large margin classifiers</strong>. The margin of the support vector machine and this gives the SVM a certain robustness, because it tries to separate the data with as a large a margin as possible. So the support vector machine is sometimes also called a large  margin classifier. [latex]min \frac{1}{2} \sum _{j&#x3D;1}^{n} \ \theta _j^2 \ s.t \ \left\{\begin{matrix} \theta^Tx^{(i)} \geq \ 1 \ \ if \ y^{(i)} &#x3D; 1\\ \theta^Tx^{(i)} \leq -1 \ \ if \ y^{(i)} &#x3D; 0\\ \end{matrix}\right.[&#x2F;latex]   In practice when applying support vector machines, when C is not very very large like that, it can do a better job ignoring the few outliers.</p>
<h2 id="Mathematics-Behind-Large-Margin-Classification"><a href="#Mathematics-Behind-Large-Margin-Classification" class="headerlink" title="Mathematics Behind Large Margin Classification"></a>Mathematics Behind Large Margin Classification</h2><p>[latex]\left \ u \right \ &#x3D; \sqrt{u_1^2 + u_2^2}[&#x2F;latex] <strong>p</strong> is the length of the projection of the vector V onto the vector U. so [latex]u^Tv &#x3D; p \cdot \left \ u \right \[&#x2F;latex] and [latex]u^Tv &#x3D; u_1 \times  v_1 + u_2 \times v_2[&#x2F;latex] so [latex]p \cdot \left \ u \right \ &#x3D; u_1 \times  v_1 + u_2 \times v_2[&#x2F;latex] <strong>SVM Decision Boundary</strong> [latex]\underset {\theta }{min} \frac{1}{2} \sum _{j&#x3D;1}^{n} \ \theta _j^2 \ s.t \ \left\{\begin{matrix} \theta^Tx^{(i)} \geq \ 1 \ \ if \ y^{(i)} &#x3D; 1\\ \theta^Tx^{(i)} \leq -1 \ \ if \ y^{(i)} &#x3D; 0\\ \end{matrix}\right.[&#x2F;latex]   <strong>if n &#x3D;&#x3D; 2:</strong> [latex]\begin{Vmatrix} u \end{Vmatrix} &#x3D; \sqrt{u_1^2 + u_2^2}[&#x2F;latex]   [latex]\frac{1}{2} (\theta _1^2 + \theta _2^2) &#x3D; \frac{1}{2} (\sqrt {\theta _1^2 + \theta _2^2})^2 &#x3D; \frac{1}{2}\left \ \theta \right \ ^2[&#x2F;latex]   <strong>So all the support vector machine is doing in the optimization objective is it’s minimizing the squared norm of the square length of the parameter vector theta.</strong> [latex]p^{(i)}[&#x2F;latex] : a projection of the i-th training example onto the parameter vector [latex]\theta [&#x2F;latex]. [latex]\theta ^Tx^{(i)} &#x3D; \theta_1 \cdot x_1^{(i)} + \theta_2 \cdot x_2^{(i)} [&#x2F;latex]   <strong>SVM Decision Boundary</strong> [latex]\underset {\theta }{min} \frac{1}{2} \sum _{j&#x3D;1}^{n} \ \theta _j^2 \ s.t \ \left\{\begin{matrix} p^{(i)} \cdot \left \ \theta \right \ \geq \ 1 \ \ if \ y^{(i)} &#x3D; 1\\ p^{(i)} \cdot \left \ \theta \right \ \leq -1 \ \ if \ y^{(i)} &#x3D; 0\\ \end{matrix}\right.[&#x2F;latex] If we can make the norm of theta smaller and therefore make the squared norm of theta smaller, <strong>which is why the SVM would choose this hypothesis</strong> on the right instead. And this is how the SVM gives rise to this large margin certification effect. Mainly, if you look at this green line, if you look at this green hypothesis we want the projections of my positive and negative examples onto theta to be large, and the only way for that to hold true this is if surrounding the green line. There’s this large margin, there’s this large gap that separates positive and negative examples is really the magnitude of this gap. The magnitude of this margin is exactly the values of P1, P2, P3 and so on. And so by making the margin large, by these tyros P1, P2, P3 and so on that’s <strong>the SVM can end up with a smaller value for the norm of theta</strong> which is what it is trying to do in the objective. And <strong>this is why this machine ends up with enlarge margin classifiers</strong> because itss trying to maximize the norm of these P1 which is the distance from the training examples to the decision boundary.</p>
<h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><ul>
<li>complex polynomial features</li>
</ul>
<p>[latex]\theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_1x_2 + \theta_4x_1^2 + \theta_5x_2^2 + \cdots[&#x2F;latex]  </p>
<ul>
<li>new denotation</li>
</ul>
<p>[latex]f_1 &#x3D; x_1, \ f_2 &#x3D; x_2, \ f_3 &#x3D; x_1x_2, \ f_4 &#x3D; x_1^2, \ f_5 &#x3D; x_2^2[&#x2F;latex] [latex]h_\theta (x) &#x3D; \theta_1f_1 + \theta_2f_2 + \cdots + \theta_nf_n[&#x2F;latex]   <strong>Gaussian Kernel</strong> [latex]f_1 &#x3D; similarity(x, l^{(1)}) &#x3D; e^{(-\frac {\left \ x - l^{(1)} \right \ ^ 2}{2\sigma ^2})}[&#x2F;latex]   [latex]\left \ x - l^{(1)} \right \ ^ 2 &#x3D; \sum _{j&#x3D;1}^{n}(x_j - l_j^{(1)})^2[&#x2F;latex]   We define some extra features using landmarks and similarity functions to learn more complex nonlinear classifiers. We <strong>use new features</strong> that are computed by Kernels, <strong>not original features</strong>.</p>
<h4 id="How-the-landmarks-are-chosen"><a href="#How-the-landmarks-are-chosen" class="headerlink" title="How the landmarks are chosen"></a>How the landmarks are chosen</h4><p>Choose the the location of my landmarks to be exactly near the locations of my m training examples. Given [latex](x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots , (x^{(m)}, y^{(m)})[&#x2F;latex] choose [latex]l^{(1)} &#x3D; x^{(1)}, l^{(2)} &#x3D; x^{(2)}, \cdots \cdots , l^{(m)} &#x3D; x^{(m)}[&#x2F;latex] Given example x :  [latex]f_1 &#x3D; similarity(x, l^{(1)})[&#x2F;latex] [latex]f_2 &#x3D; similarity(x, l^{(2)})[&#x2F;latex] [latex]\cdots [&#x2F;latex] **Cost Function : ** [latex]minC\sum _{i&#x3D;1}^{m}[y^{(i)}cost_1(\theta^Tf^{(i)}) + (1-y^{(i)})cost_0(\theta^Tf^{(i)})]+\frac{1}{2}\sum_{j&#x3D;1}^{n&#x3D;m}\theta_j^2[&#x2F;latex]   Using kernels with logistic regression is going too very slow.</p>
<h4 id="How-to-choose-latex-C-and-sigma-x2F-latex"><a href="#How-to-choose-latex-C-and-sigma-x2F-latex" class="headerlink" title="How to choose [latex]C \ and \ \sigma[&#x2F;latex]"></a>How to choose [latex]C \ and \ \sigma[&#x2F;latex]</h4><p>[latex]C &#x3D; 1 \ &#x2F; \ \lambda[&#x2F;latex]</p>
<ul>
<li>[latex]C[&#x2F;latex] big: overfitting, higher variance</li>
<li>[latex]C[&#x2F;latex] small: underfitting, higher bias</li>
<li>[latex]\sigma[&#x2F;latex] big : lower variance, higher bias</li>
<li>[latex]\sigma[&#x2F;latex] small : lower bias, higher variance</li>
</ul>
<h2 id="Using-An-SVM"><a href="#Using-An-SVM" class="headerlink" title="Using An SVM"></a>Using An SVM</h2><p><strong>Some library function :</strong></p>
<ul>
<li>liblinear</li>
<li>libsvm</li>
</ul>
<p><strong>There are a few things need to do :</strong></p>
<ol>
<li>parameter’s C</li>
<li>choose the kernel (If we decide not to use any kernel. And the idea of no kernel is also called a <strong>linear kernel</strong>)</li>
</ol>
<h4 id="Logistic-Regression-or-Support-Vector-Machine"><a href="#Logistic-Regression-or-Support-Vector-Machine" class="headerlink" title="Logistic Regression or Support Vector Machine"></a>Logistic Regression or Support Vector Machine</h4><ul>
<li>n : number of features</li>
<li>m : number of training examples</li>
</ul>
<ol>
<li>n &gt;&gt; m, Logistic Regression or Linear Kernel</li>
<li>n small, and m middle, like 1 &lt; n &lt; 1000, 10 &lt; m &lt; 10000, SVM with Gaussian Kernel</li>
<li>n small, and m big, like 1 &lt; n &lt; 1000, 50000 &lt; m, SVM is slower, so try to munually create more features and then use logistic regression or an SVM without the Kernel</li>
</ol>
<p>Well for all of these problems, for all of these different regimes, a well designed <strong>neural network</strong> is likely to work well as well. The <strong>algorithm</strong> does matter, but what often matters even more is things like, <strong>how much data</strong> do you have. And <strong>how skilled</strong> are you, how good are you at doing <strong>error analysis and debugging learning algorithms</strong>, figuring out how to <strong>design new features</strong> and <strong>figuring out what other features</strong> to give you learning algorithms and so on.</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/04/01/11-machine-learning-system-design/" rel="prev" title="11 Machine Learning System Design">
      <i class="fa fa-chevron-left"></i> 11 Machine Learning System Design
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/04/02/13-clustering/" rel="next" title="13 Clustering">
      13 Clustering <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Optimization-Objective"><span class="nav-number">1.</span> <span class="nav-text">Optimization Objective</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Large-Margin-Intuition"><span class="nav-number">2.</span> <span class="nav-text">Large Margin Intuition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mathematics-Behind-Large-Margin-Classification"><span class="nav-number">3.</span> <span class="nav-text">Mathematics Behind Large Margin Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernels"><span class="nav-number">4.</span> <span class="nav-text">Kernels</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#How-the-landmarks-are-chosen"><span class="nav-number">4.0.1.</span> <span class="nav-text">How the landmarks are chosen</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#How-to-choose-latex-C-and-sigma-x2F-latex"><span class="nav-number">4.0.2.</span> <span class="nav-text">How to choose [latex]C \ and \ \sigma[&#x2F;latex]</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Using-An-SVM"><span class="nav-number">5.</span> <span class="nav-text">Using An SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Logistic-Regression-or-Support-Vector-Machine"><span class="nav-number">5.0.1.</span> <span class="nav-text">Logistic Regression or Support Vector Machine</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Water"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Water</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">216</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/linmonsv" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;linmonsv" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qin2@qq.com" title="E-Mail → mailto:qin2@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Water</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
