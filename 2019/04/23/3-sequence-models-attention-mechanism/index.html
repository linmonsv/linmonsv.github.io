<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Various sequence to sequence architecturesSequence to sequence models which are useful for everything from machine translation to speech recognition.  translate image captioning  Picking the most like">
<meta property="og:type" content="article">
<meta property="og:title" content="3 Sequence models &amp; Attention mechanism">
<meta property="og:url" content="http://example.com/2019/04/23/3-sequence-models-attention-mechanism/index.html">
<meta property="og:site_name" content="Water&#39;s Home">
<meta property="og:description" content="Various sequence to sequence architecturesSequence to sequence models which are useful for everything from machine translation to speech recognition.  translate image captioning  Picking the most like">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/Why_not_a_greedy_search.png">
<meta property="og:image" content="http://example.com/img/Error_analysis_on_beam_search.png">
<meta property="og:image" content="http://example.com/img/Bleu_details.png">
<meta property="og:image" content="http://example.com/img/Computing_attention.png">
<meta property="og:image" content="http://example.com/img/CTC_cost_for_speech_recognition.png">
<meta property="og:image" content="http://example.com/img/Trigger_word_detection_algorithm.png">
<meta property="article:published_time" content="2019-04-23T05:47:26.000Z">
<meta property="article:modified_time" content="2022-07-05T01:29:39.508Z">
<meta property="article:author" content="Water">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/Why_not_a_greedy_search.png">

<link rel="canonical" href="http://example.com/2019/04/23/3-sequence-models-attention-mechanism/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>3 Sequence models & Attention mechanism | Water's Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Water's Home</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Just another Life Style</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/04/23/3-sequence-models-attention-mechanism/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Water">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Water's Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          3 Sequence models & Attention mechanism
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-04-23 13:47:26" itemprop="dateCreated datePublished" datetime="2019-04-23T13:47:26+08:00">2019-04-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-05 09:29:39" itemprop="dateModified" datetime="2022-07-05T09:29:39+08:00">2022-07-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine-learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep-learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/Deep-Learning-Specialization-Offered-By-deeplearning-ai/" itemprop="url" rel="index"><span itemprop="name">Deep Learning Specialization Offered By deeplearning.ai</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Various-sequence-to-sequence-architectures"><a href="#Various-sequence-to-sequence-architectures" class="headerlink" title="Various sequence to sequence architectures"></a>Various sequence to sequence architectures</h2><p>Sequence to sequence models which are useful for everything from machine translation to speech recognition.</p>
<ul>
<li>translate</li>
<li>image captioning</li>
</ul>
<h2 id="Picking-the-most-likely-sentence"><a href="#Picking-the-most-likely-sentence" class="headerlink" title="Picking the most likely sentence"></a>Picking the most likely sentence</h2><p><img src="/img/Why_not_a_greedy_search.png"></p>
<h2 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h2><p>You don’t want to output a random English translation, you want to output <strong>the best and the most likely</strong> English translation. <strong>Beam search</strong> is the most widely used algorithm to do this. So, whereas greedy search will pick only the one most likely words and move on, Beam Search instead can <strong>consider multiple alternatives</strong>.  So, the Beam Search algorithm has a parameter called B, which is called the <strong>beam width</strong>. <em>Notice that what we ultimately care about in this second step would be to find the pair of the first and second words that is most likely. so it’s not just a second where is most likely but <strong>the pair of the first and second words most likely</strong>.</em> <em><strong>Evaluate all of these 30000 options according to the probability of the first and second words and then pick the top three</strong>. Because of beam width is equal to three, every step you instantiate three copies of the network to evaluate these partial sentence fragments and the output.</em> <em>And it’s because of beam width is equal to three that you have three copies of the network with different choices for the first words,</em> <strong>Beam search</strong> will usually find a <strong>much better</strong> output sentence <strong>than greedy search</strong>.</p>
<h2 id="Refinements-to-Beam-Search"><a href="#Refinements-to-Beam-Search" class="headerlink" title="Refinements to Beam Search"></a>Refinements to Beam Search</h2><p><strong>Length normalization</strong> is a small change to the beam search algorithm that can help you <strong>get much better results</strong>. <strong>Numerical underflow</strong>. Meaning that it’s too small for the floating part representation in your computer to store accurately. So in most implementations, you <strong>keep track of the sum of logs of the probabilities</strong> rather than the production of probabilities. <em>Instead of using this as the objective you’re trying to maximize, one thing you could do is normalize this by the number of words in your translation. And so this takes the average of the log of the probability of each word.</em> <em>And this significantly reduces the penalty for outputting longer translations.</em> And in practice, as a heuristic instead of dividing by Ty, by the number of words in the output sentence, sometimes you use a softer approach. We have Ty to the <strong>power of alpha</strong>, where maybe alpha is equal to 0.7. So if alpha was equal to 1, then yeah, completely normalizing by length. If alpha was equal to 0, then, well, Ty to the 0 would be 1, then you’re just not normalizing at all. And this is somewhat in <strong>between full normalization and no normalization</strong>. And alpha’s another hyper parameter of algorithm that you can tune to try to get the best results. Pick the one that achieves the highest value on this normalized log probability objective. Sometimes it’s called a <strong>normalized log likelihood objective</strong>. <strong>In production systems</strong>, it’s not uncommon to see a beam width <strong>maybe around 10</strong>. <strong>Exact search algorithms :</strong> </p>
<ul>
<li>BFS, Breadth First Search</li>
<li>DFS, Depth First Search</li>
</ul>
<p><strong>Beam search runs much faster but does not guarantee to find the exact maximum</strong> for this arg max that you would like to find.</p>
<h2 id="Error-analysis-in-beam-search"><a href="#Error-analysis-in-beam-search" class="headerlink" title="Error analysis in beam search"></a>Error analysis in beam search</h2><p>Beam search is an approximate search algorithm, also called a heuristic search algorithm. How <strong>error analysis</strong> interacts with beam search and how you can figure out whether it is the <strong>beam search algorithm</strong> that’s causing problems and worth spending time on. Or whether it might be your <strong>RNN model</strong> that is causing problems and worth spending time on. <strong>Model :</strong> </p>
<ul>
<li>RNN model (neural network model or sequence to sequence model)<ul>
<li>It’s really an encoder and a decoder.</li>
<li>P(yx)</li>
</ul>
</li>
<li>Beam search algorithm</li>
</ul>
<p>[latex]\left\{\begin{matrix} P(y^{*}x) &amp; use \ model\\ P(\hat yx) &amp; use \ RNN \end{matrix}\right.[&#x2F;latex]   <img src="/img/Error_analysis_on_beam_search.png"></p>
<h2 id="Bleu-Score"><a href="#Bleu-Score" class="headerlink" title="Bleu Score"></a>Bleu Score</h2><p>How to <strong>evaluate a machine translation system</strong></p>
<p>The way this is done conventionally is through something called the BLEU score.</p>
<p>What the BLEU score does is given a machine generated translation, it allows you to automatically compute a score that measures how good is that machine translation. <strong>BLEU, by the way, stands for bilingual evaluation understudy</strong>. <strong>Tthe intuition behind the BLEU score</strong> is we’re going to look at the machine generated output and see if the types of words it generates appear in at least one of the human generated references. <img src="/img/Bleu_details.png">   The reason the BLEU score was revolutionary for machine translation was because this gave a <strong>pretty good, by no means perfect</strong>, but <strong>pretty good single real number evaluation metric</strong>. And so that accelerated the progress of the entire field of machine translation. Today, <strong>BLEU score is used to evaluate</strong> many systems that generate text, such as <strong>machine translation systems</strong>, as well as the example I showed briefly earlier of <strong>image captioning systems</strong>.</p>
<h2 id="Attention-Model-Intuition"><a href="#Attention-Model-Intuition" class="headerlink" title="Attention Model Intuition"></a>Attention Model Intuition</h2><p>Attention Model, that makes RNN work much better.</p>
<ul>
<li>It’s just difficult to get in your network to memorize a super long sentence.</li>
<li>But with an Attention Model, machine translation systems performance can look like this, because by working one part of the sentence at a time, <ul>
<li>What the Attention Model would be computing is a set of attention weights.</li>
</ul>
</li>
</ul>
<h2 id="Attention-Model"><a href="#Attention-Model" class="headerlink" title="Attention Model"></a>Attention Model</h2><p><img src="/img/Computing_attention.png"> This algorithm runs in quadratic cost, Although in machine translation applications where neither input nor output sentences is usually that long maybe quadratic cost is actually acceptable.</p>
<h2 id="Speech-recognition"><a href="#Speech-recognition" class="headerlink" title="Speech recognition"></a>Speech recognition</h2><p>One of the most exciting developments were sequence-to-sequence models has been the <strong>rise of very accurate speech recognition</strong>. <strong>A common pre-processing step for audio data</strong> is to run your raw audio clip and generate a spectrogram. So, this is the plots where the horizontal axis is time, and the vertical axis is frequencies, and intensity of different colors shows the amount of energy. Once upon a time, speech recognition systems used to be built using phonemes and this where, hand-engineered basic units of cells. But <strong>with end-to-end deep learning, we’re finding that phonemes representations are no longer necessary</strong>. <img src="/img/CTC_cost_for_speech_recognition.png"></p>
<h2 id="Trigger-Word-Detection"><a href="#Trigger-Word-Detection" class="headerlink" title="Trigger Word Detection"></a>Trigger Word Detection</h2><p>When the rise of speech recognition have been more and more devices you can <strong>wake up with your voice</strong> and those are sometimes called <strong>trigger word detection systems</strong>. <img src="/img/Trigger_word_detection_algorithm.png">   Then in the training sets you can set the target labels to be zero for everything before that point and right after that to set the target label of one.And then if a little bit later on the trigger word was said again, and the trigger was said at this point, then you can again set the target label to be one right after that.</p>
<p>One slight <strong>disadvantage</strong> of this is it creates a very imbalanced training set.So a lot more zeros than ones.</p>
<p><strong>Instead of setting only a single time step to output one</strong>, you can actually make an output a few ones for several times or for a fixed period of time before reverting back to zero. So and that, slightly evens out the ratio of ones to zeros. But this is a little bit of a hack.</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/04/23/2-natural-language-processing-and-word-embeddings/" rel="prev" title="2 Natural Language Processing and Word Embeddings">
      <i class="fa fa-chevron-left"></i> 2 Natural Language Processing and Word Embeddings
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/05/06/first-line-of-code-version-2-notes/" rel="next" title="First Line of Code (Version 2) Notes">
      First Line of Code (Version 2) Notes <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Various-sequence-to-sequence-architectures"><span class="nav-number">1.</span> <span class="nav-text">Various sequence to sequence architectures</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Picking-the-most-likely-sentence"><span class="nav-number">2.</span> <span class="nav-text">Picking the most likely sentence</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Beam-Search"><span class="nav-number">3.</span> <span class="nav-text">Beam Search</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Refinements-to-Beam-Search"><span class="nav-number">4.</span> <span class="nav-text">Refinements to Beam Search</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Error-analysis-in-beam-search"><span class="nav-number">5.</span> <span class="nav-text">Error analysis in beam search</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bleu-Score"><span class="nav-number">6.</span> <span class="nav-text">Bleu Score</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Attention-Model-Intuition"><span class="nav-number">7.</span> <span class="nav-text">Attention Model Intuition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Attention-Model"><span class="nav-number">8.</span> <span class="nav-text">Attention Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Speech-recognition"><span class="nav-number">9.</span> <span class="nav-text">Speech recognition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Trigger-Word-Detection"><span class="nav-number">10.</span> <span class="nav-text">Trigger Word Detection</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Water"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Water</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">216</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/linmonsv" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;linmonsv" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qin2@qq.com" title="E-Mail → mailto:qin2@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Water</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
