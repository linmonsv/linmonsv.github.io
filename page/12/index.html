<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/12/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-1-introduction-to-deep-learning" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/09/1-introduction-to-deep-learning/" class="article-date">
  <time class="dt-published" datetime="2019-04-09T05:55:12.000Z" itemprop="datePublished">2019-04-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep-learning</a>►<a class="article-category-link" href="/categories/deep-learning/Deep-Learning-Specialization-Offered-By-deeplearning-ai/">Deep Learning Specialization Offered By deeplearning.ai</a>►<a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>►<a class="article-category-link" href="/categories/machine-learning/Deep-Learning/">Deep Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/09/1-introduction-to-deep-learning/">1 Introduction to Deep Learning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Welcome"><a href="#Welcome" class="headerlink" title="Welcome"></a>Welcome</h2><p>Deep Learning has aready transformed the traditional internet businesses</p>
<h2 id="What-is-a-Neural-Network"><a href="#What-is-a-Neural-Network" class="headerlink" title="What is a Neural Network"></a>What is a Neural Network</h2><p>You probably find them to be most useful, most powerful, in supervised learning settings. Meaning that you’re trying to take an input x and map it some output y,</p>
<h2 id="Supervised-Learning-with-Neural-Networks"><a href="#Supervised-Learning-with-Neural-Networks" class="headerlink" title="Supervised Learning with Neural Networks"></a>Supervised Learning with Neural Networks</h2><p><strong>It turns out that so far, almost all the economic value created by neural networks has been through one type of machine learning, called supervised learning.</strong> Possibly the single most lucrative application of deep learning today is online advertising.</p>
<ul>
<li>Computer Vision</li>
<li>Speech Recognition</li>
<li>Autonomous Driving</li>
</ul>
<p>It turns out that slightly different types of neural networks are useful for different applications. <strong>CNN (Convolutional Neural Network)</strong> <strong>RNN (Recurrent Neural Network)</strong></p>
<ul>
<li>Structured Data means basically databases of data.</li>
<li>In contrast, unstructured data refers to things like audio, raw audio, or images where you might want to recognize what’s in the image or text. Historically, it has been much harder for computers to make sense of unstructured data compared to structured data.</li>
</ul>
<p><strong>It turns out that a lot of short term economic value that neural networks are creating has also been on structured data</strong>, such as much better advertising systems, much better profit recommendations, and just a much better ability to process the giant databases that many companies have to make accurate predictions from them.</p>
<h2 id="Why-is-Deep-Learning-taking-off"><a href="#Why-is-Deep-Learning-taking-off" class="headerlink" title="Why is Deep Learning taking off?"></a>Why is Deep Learning taking off?</h2><p>Go over some of the main drivers behind the rise of deep learning because I think this will help you better spot the best opportunities within your own organization to apply these to. More and more and more data have been collected so over the last 20 years for a lot of applications we just accumulate a lot more data more than traditional learning algorithms were able to effectively take advantage of. <strong>Hit very high level of performance :</strong> </p>
<ol>
<li>Train a big enough neural network</li>
<li>Throw more data</li>
</ol>
<p><strong>If you don’t have a lot of training data is often up to your skill at hand engineering features that determines the performance.</strong> The performance depends much more on your skill at hand engineer features and other normal details of the algorithms and there’s only in this some big data regions very large training sets very large M regions in the right that we more consistently see largely neural nets dominating the other approaches and so</p>
<ul>
<li><strong>Data</strong></li>
<li><strong>Computation</strong></li>
<li><strong>Algorithmic Innovation</strong></li>
</ul>
<p>One of the huge breakthroughs in neural networks has been switching from a sigmoid function which looks like this to a ReLU function.</p>
<ul>
<li>Ultimately the impact of this algorithmic innovation was it really help computation so there remains quite a lot of examples like this of where we change the algorithm because it allows that code to <strong>run much faster</strong> and this allows us to <strong>train bigger neural networks</strong> or to do so <strong>within reasonable amount of time</strong> even when we have a large network with a lot of data.</li>
<li>It turns out the process of training your network it is very intuitive often. you have an idea for a neural network architecture and so you implement your idea and code. Implementing your idea then lets you run an experiment which tells you how well your neural network does and then by looking at it you go back to change the details of your neural network and then you go around this circle over and over and when your neural network takes a long time to train it just takes a long time to go around this cycle and there’s a huge difference in your productivity building effective neural networks.</li>
</ul>
<p><strong>Faster Computation —&gt; Iterate Much Faster —&gt; Improve Ideas Much Faster</strong></p>
<h2 id="About-this-Course"><a href="#About-this-Course" class="headerlink" title="About this Course"></a>About this Course</h2><p><strong>Just use the multiple choice questions to check your understanding. And dont’ review, you can try again and again until you get them all right.</strong></p>
<h2 id="Course-Resources"><a href="#Course-Resources" class="headerlink" title="Course Resources"></a>Course Resources</h2><p>If you have any questions or you want to discuss anything with the classmates or … the best place to do that is <strong>the discussion forum</strong>.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/09/1-introduction-to-deep-learning/" data-id="cl56gcvsy0011lgch8rkadbtf" data-title="1 Introduction to Deep Learning" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-1762" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/1762/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T08:04:09.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/uncategorized/">uncategorized</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/1762/">Untitled Post - 31</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/1762/" data-id="cl56gcvu5003vlgchaf53b0gm" data-title="Untitled Post - 31" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-18-application-example-photo-ocr" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/18-application-example-photo-ocr/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T07:56:52.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>►<a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>►<a class="article-category-link" href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/">Machine Learning Offered By Stanford University</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/18-application-example-photo-ocr/">18 Application Example: Photo OCR</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Problem-Description-and-Pipeline"><a href="#Problem-Description-and-Pipeline" class="headerlink" title="Problem Description and Pipeline"></a>Problem Description and Pipeline</h2><ol>
<li>Text detection</li>
<li>Character segmentation</li>
<li>Character classification</li>
</ol>
<h2 id="Sliding-Windows"><a href="#Sliding-Windows" class="headerlink" title="Sliding Windows"></a>Sliding Windows</h2><p>Go out and collect large training sets of positive and negative examples. Take that green rectangle and we slide it over a bit and then run that new image patch through our classifier to decide if there’s a pedestrian there.</p>
<h2 id="Getting-Lots-of-Data-and-Artificial-Data"><a href="#Getting-Lots-of-Data-and-Artificial-Data" class="headerlink" title="Getting Lots of Data and Artificial Data"></a>Getting Lots of Data and Artificial Data</h2><ol>
<li>artificial data synthesis</li>
<li>just collect the data and you label it yourself</li>
<li>crowd sourcing</li>
</ol>
<h2 id="Ceiling-Analysis-What-Part-of-the-Pipeline-to-Work-on-Next"><a href="#Ceiling-Analysis-What-Part-of-the-Pipeline-to-Work-on-Next" class="headerlink" title="Ceiling Analysis What Part of the Pipeline to Work on Next"></a>Ceiling Analysis What Part of the Pipeline to Work on Next</h2><p>Where should you allocate resources? Which of these boxes is most worth your efforts, trying to improve the performance of.</p>
<ol>
<li>choose one module</li>
<li>provide it the correct text detection outputs</li>
<li>And then, use the same evaluation metric as before, to measure what is the overall accuracy of the entire system</li>
<li>go to step 1, but choose another one</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/18-application-example-photo-ocr/" data-id="cl56gcvu5003xlgchfru5h3nm" data-title="18 Application Example: Photo OCR" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-17-large-scale-machine-learning" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/17-large-scale-machine-learning/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T07:32:45.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>►<a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>►<a class="article-category-link" href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/">Machine Learning Offered By Stanford University</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/17-large-scale-machine-learning/">17 Large Scale Machine Learning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Learning-With-Large-Datasets"><a href="#Learning-With-Large-Datasets" class="headerlink" title="Learning With Large Datasets"></a>Learning With Large Datasets</h2><p>Draw a learning curve and determine if more data needs to be collected.</p>
<h2 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h2><p><strong>Cost Function in SGD :</strong> [latex]cost(\theta, (x^{(i)}, y^{(i)})) &#x3D; \frac {1}{2}(h_{\theta}(x^{(i)})-y^{(i)})^2[&#x2F;latex]</p>
<ol>
<li>randomly shuffle the data set</li>
<li>a little gradient descent step using just one single training example</li>
<li>maybe head in a bad direction, generally move the parameters in the direction of the global minimum, but not always</li>
<li>it ends up doing is wandering around continuously in some region that’s in some region close to the global minimum</li>
</ol>
<h2 id="Mini-Batch-Gradient-Descent"><a href="#Mini-Batch-Gradient-Descent" class="headerlink" title="Mini-Batch Gradient Descent"></a>Mini-Batch Gradient Descent</h2><p>In <strong>Batch gradient descent</strong> we will use <strong>all m examples</strong> in each generation. Whereas in <strong>Stochastic gradient descent</strong> we will use a <strong>single example</strong> in each generation. What <strong>Mini-batch gradient descent</strong> does is somewhere <strong>in between</strong>.</p>
<h2 id="Stochastic-Gradient-Descent-Convergence"><a href="#Stochastic-Gradient-Descent-Convergence" class="headerlink" title="Stochastic Gradient Descent Convergence"></a>Stochastic Gradient Descent Convergence</h2><p>[latex]\alpha &#x3D; \frac {const1}{iterationNumber + const2}[&#x2F;latex] We can <strong>compute the cost function on the last 1000 examples or so</strong>. And we can use this method both to make sure the stochastic gradient descent is okay and is converging or to use it to tune the learning rate alpha.</p>
<h2 id="Online-Learning"><a href="#Online-Learning" class="headerlink" title="Online Learning"></a>Online Learning</h2><p>The online learning setting allows us to model problems where we have <strong>a continuous flood or a continuous stream of data coming in</strong> and we would like an algorithm to learn from that. We learn using that example like so <strong>and then we throw that example away</strong>. If you really have a continuous stream of data, then an online learning algorithm can be very effective. If you have <strong>a changing pool of users</strong>, or if the things you’re trying to <strong>predict are slowly changing</strong> like your user taste is slowly changing, the online learning algorithm can slowly adapt your learned hypothesis to whatever the latest sets of user behaviors are like as well.</p>
<h2 id="Map-Reduce-and-Data-Parallelism"><a href="#Map-Reduce-and-Data-Parallelism" class="headerlink" title="Map Reduce and Data Parallelism"></a>Map Reduce and Data Parallelism</h2><p>In the MapReduce idea, one way to do, is split this training set in to different subsets and use many different machines.</p>
<ul>
<li>multi-core machine</li>
<li>multiple machines</li>
<li>numerical linear algebra libraries</li>
<li>like Hadoop</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/17-large-scale-machine-learning/" data-id="cl56gcvu3003tlgchcz56b7nf" data-title="17 Large Scale Machine Learning" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-16-recommender-systems" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/16-recommender-systems/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T06:48:38.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>►<a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>►<a class="article-category-link" href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/">Machine Learning Offered By Stanford University</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/16-recommender-systems/">16 Recommender Systems</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><ol>
<li>an important application of machine learning</li>
<li>this idea of learning the features</li>
</ol>
<h2 id="Content-Based-Recommendations"><a href="#Content-Based-Recommendations" class="headerlink" title="Content Based Recommendations"></a>Content Based Recommendations</h2><p><strong>user j ‘s parameter vector :</strong> [latex]\theta^{(j)}[&#x2F;latex] <strong>movie i’s feature vector :</strong> [latex]x^{(i)}[&#x2F;latex] <strong>Predicting rating:</strong> [latex](\theta^{(j)})^Tx^{(i)}[&#x2F;latex] <strong>user [latex]j[&#x2F;latex] ‘s cost function :</strong> [latex]\underset {\theta ^{(j)}}{min} \frac {1}{2} \sum _{i:r(i,j)&#x3D;1} ((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+ \frac {\lambda}{2}(\theta_k^{(j)})^2[&#x2F;latex] <strong>all user’s cost function :</strong> [latex]\underset {\theta ^{(j)}, \cdots , \theta ^{(n_u)}}{min} \frac {1}{2} \sum _{j&#x3D;1}^{n_u} \sum _{i:r(i,j)&#x3D;1} ((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+ \frac {\lambda}{2} \sum_{j&#x3D;1}^{n_u} \sum_{k&#x3D;1}^{n} (\theta_k^{(j)})^2[&#x2F;latex] **Gradient descent : ** [latex]\left\{\begin{matrix} \theta_k^{(j)} :&#x3D; \theta_k^{(j)} - \alpha \sum_{i:r(i,j)&#x3D;1} ((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})x_{k}^{(i)} &amp; \ (for \ k \ &#x3D; \ 0) \\ \theta_k^{(j)} :&#x3D; \theta_k^{(j)} - \alpha (\sum_{i:r(i,j)&#x3D;1} ((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})x_{k}^{(i)} + \lambda \theta_{k}^{(j)}) &amp; \ (for \ k \ \neq \ 0) \end{matrix}\right.[&#x2F;latex]  </p>
<h2 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h2><p><strong>No User’s Parameter and No Movie’s Features, you can do this.</strong> <em>The term <strong>collaborative filtering</strong> refers to the observation that when you run this algorithm with a large set of users, what all of these users are effectively doing are sort of collaboratively or collaborating to get better movie ratings for everyone because with every user rating some subset with the movies, every user is helping the algorithm a little bit to learn better features, and then by helping– by rating a few movies myself, I will be helping the system learn better features and then these features can be used by the system to make better movie predictions for everyone else. And so there is a sense of collaboration where every user is helping the system learn better features for the common good. This is this collaborative filtering.</em></p>
<h2 id="Collaborative-Filtering-Algorithm"><a href="#Collaborative-Filtering-Algorithm" class="headerlink" title="Collaborative Filtering Algorithm"></a>Collaborative Filtering Algorithm</h2><ol>
<li>Initialize x and theta to small random values</li>
<li>minimize the cost function using great intercepts or one of the advance optimization algorithms</li>
<li>predict</li>
</ol>
<h2 id="Vectorization-Low-Rank-Matrix-Factorization"><a href="#Vectorization-Low-Rank-Matrix-Factorization" class="headerlink" title="Vectorization Low Rank Matrix Factorization"></a>Vectorization Low Rank Matrix Factorization</h2><p>A user has recently been looking at one product. Are there <strong>other related products</strong> that you could <strong>recommend</strong> to this user? If you can find a different movie i, j, so that the distance between [latex]x^{(i)}[&#x2F;latex] and [latex]x^{(j)}[&#x2F;latex] is small, then this is a pretty strong indication that, you know, movies j and i are somehow similar Use learned features to find what might be movies and what might be products that aren’t related to each other.</p>
<h2 id="Implementational-Detail-Mean-Normalization"><a href="#Implementational-Detail-Mean-Normalization" class="headerlink" title="Implementational Detail Mean Normalization"></a>Implementational Detail Mean Normalization</h2><p><strong>If a user has not evaluated any movies, which movie should we recommend?</strong> The idea of mean normalization will let us fix this problem.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/16-recommender-systems/" data-id="cl56gcvu2003rlgch7cqqbpzp" data-title="16 Recommender Systems" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-15-anomaly-detection" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/15-anomaly-detection/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T03:52:31.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>►<a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>►<a class="article-category-link" href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/">Machine Learning Offered By Stanford University</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/15-anomaly-detection/">15 Anomaly Detection</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Problem-Motivation"><a href="#Problem-Motivation" class="headerlink" title="Problem Motivation"></a>Problem Motivation</h2><p>It’s mainly for unsupervised problem, that there’s some aspects of it that are also very similar to sort of the supervised learning problem. <strong>some examples :</strong> </p>
<ul>
<li>detect strange behavior or fraudulent behavior</li>
<li>manufacturing</li>
<li>monitoring computers in a data center</li>
</ul>
<h2 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h2><h4 id="Gaussian-distribution"><a href="#Gaussian-distribution" class="headerlink" title="Gaussian distribution"></a>Gaussian distribution</h4><p>[latex]x\sim N(\mu , \sigma ^2)[&#x2F;latex]  </p>
<h4 id="Gaussian-probability-density"><a href="#Gaussian-probability-density" class="headerlink" title="Gaussian probability density"></a>Gaussian probability density</h4><p>[latex]p(x, \mu , \sigma ^2) &#x3D; \frac {1}{\sqrt{2\pi }\sigma } exp(-\frac {(x - \mu)^2}{2 \sigma ^2})[&#x2F;latex]  </p>
<h4 id="The-location-of-the-center-of-this-bell-shaped-curve"><a href="#The-location-of-the-center-of-this-bell-shaped-curve" class="headerlink" title="The location of the center of this bell-shaped curve"></a>The location of the center of this bell-shaped curve</h4><p>[latex]\mu &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{m}x^{(i)}[&#x2F;latex]  </p>
<h4 id="The-width-of-this-bell-shaped-curve"><a href="#The-width-of-this-bell-shaped-curve" class="headerlink" title="The width of this bell-shaped curve"></a>The width of this bell-shaped curve</h4><p>[latex]\sigma ^ 2 &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{m} (x^{(i)} - \mu) ^2[&#x2F;latex]   <strong>Notice :</strong> The formula here  we use [latex]m[&#x2F;latex] instead of [latex]m - 1[&#x2F;latex] which is used in a statistics.</p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p>Address anomaly detection : [latex]\mu _j &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{m}x^{(i)} _j[&#x2F;latex]   [latex]\sigma ^ 2 _j &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{m} (x^{(i)}_j - \mu _j) ^2[&#x2F;latex]   [latex]p(x) &#x3D; \prod _{j&#x3D;1}^{n}p(x_j; \mu _j, \sigma ^2_j) &#x3D; \prod _{j&#x3D;1}^{1}\frac {1}{\sqrt{2\pi } \sigma _j} exp(-\frac {(x_j - \mu_j)^2}{2 \sigma ^2_j})[&#x2F;latex]   <strong>If [latex]p(x) &lt; \varepsilon [&#x2F;latex], it’s anomaly.</strong></p>
<h2 id="Developing-and-Evaluating-an-Anomaly-Detection-System"><a href="#Developing-and-Evaluating-an-Anomaly-Detection-System" class="headerlink" title="Developing and Evaluating an Anomaly Detection System"></a>Developing and Evaluating an Anomaly Detection System</h2><p><strong>How to develop and evaluate an algorithm ?</strong></p>
<ol>
<li>Take the training sets and fit the model [latex]p(x)[&#x2F;latex]</li>
<li>On the cross validation of the test set, try to use different [latex]\varepsilon[&#x2F;latex], and then compute the F1 score</li>
<li>After choosed [latex]\varepsilon[&#x2F;latex], evaluation of the algorithm on the test sets</li>
</ol>
<h2 id="Anomaly-Detection-vs-Supervised-Learning"><a href="#Anomaly-Detection-vs-Supervised-Learning" class="headerlink" title="Anomaly Detection vs. Supervised Learning"></a>Anomaly Detection vs. Supervised Learning</h2><p>[table id&#x3D;3 &#x2F;]</p>
<h2 id="Choosing-What-Features-to-Use"><a href="#Choosing-What-Features-to-Use" class="headerlink" title="Choosing What Features to Use"></a>Choosing What Features to Use</h2><ol>
<li>model the features using this sort of Gaussian distribution (play with different transformations of the data in order to make it look more Gaussian)</li>
<li>do an error analysis procedure to come up with features for an anomaly detection algorithm</li>
<li>create new features by combining me features</li>
</ol>
<h2 id="Multivariate-Gaussian-Distribution"><a href="#Multivariate-Gaussian-Distribution" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h2><p>[latex]p(x) &#x3D; \prod _{j&#x3D;1}^{n}p(x_j; \mu, \sigma ^2_j) &#x3D; \prod _{j&#x3D;1}^{n}\frac {1}{\sqrt{2\pi } \sigma _j} exp(-\frac {(x_j - \mu_j)^2}{2 \sigma ^2_j})[&#x2F;latex]   [latex]\mu &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{m}x^{(i)}[&#x2F;latex]   [latex]\sum &#x3D; \frac {1}{m} \sum_{i&#x3D;1}^{m} (x^{(i)} - \mu )(x^{(i)} - \mu )^T &#x3D; \frac {1}{m} (X - \mu)^T(X - \mu)[&#x2F;latex]   [latex]p(x) &#x3D; \frac {1}{(2 \pi)^{\frac {n}{2}}\left \sum \right ^{\frac {1}{2}}} exp(-\frac {1}{2} (x-\mu)^T\sum ^{-1}(x-\mu))[&#x2F;latex]   [table id&#x3D;4 &#x2F;]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/15-anomaly-detection/" data-id="cl56gcvu1003olgch78yeeibo" data-title="15 Anomaly Detection" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-gaussian-distribution-vs-multivariate-gaussian-distribution" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/gaussian-distribution-vs-multivariate-gaussian-distribution/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T03:34:31.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/uncategorized/">uncategorized</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/gaussian-distribution-vs-multivariate-gaussian-distribution/">Gaussian Distribution vs Multivariate Gaussian Distribution</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>[[“Gaussian Distribution “,”Multivariate Gaussian Distribution”],[“Manually create features to capture anomalies”,”Automatically captures correlations between features”],[“Computationally cheaper”,””],[“”,”Must have m &gt; 10n or else sum is non-invertible”]]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/gaussian-distribution-vs-multivariate-gaussian-distribution/" data-id="cl56gcvvv0095lgchfgw4e22m" data-title="Gaussian Distribution vs Multivariate Gaussian Distribution" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-anomaly-detection-vs-supervised-learning-2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/08/anomaly-detection-vs-supervised-learning-2/" class="article-date">
  <time class="dt-published" datetime="2019-04-08T03:00:34.000Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/uncategorized/">uncategorized</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/08/anomaly-detection-vs-supervised-learning-2/">Anomaly Detection vs. Supervised Learning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>[[“Anomaly Detection”,”Supervised Learning”],[“very small number of positive, and a relatively large number of negative examples”,”a reasonably large number of both positive and negative examples”],[“many different types of anomalies”,”have enough positive examples for an algorithm to get a sense of what the positive examples are like”],[“future anomalies may look nothing like the ones you’ve seen so far”,””],[“fraud detection, manufacturing, data center”,”SPAM email, weather prediction, classifying cancers”]]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/08/anomaly-detection-vs-supervised-learning-2/" data-id="cl56gcvv2006llgchd6194r8c" data-title="Anomaly Detection vs. Supervised Learning" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-upgrade-to-visual-studio-2019-build-problems" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/04/upgrade-to-visual-studio-2019-build-problems/" class="article-date">
  <time class="dt-published" datetime="2019-04-04T03:09:13.000Z" itemprop="datePublished">2019-04-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/operating-system/">operating-system</a>►<a class="article-category-link" href="/categories/operating-system/Windows/">Windows</a>►<a class="article-category-link" href="/categories/windows/">windows</a>►<a class="article-category-link" href="/categories/windows/Visual-Studio/">Visual Studio</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/04/upgrade-to-visual-studio-2019-build-problems/">Upgrade to Visual Studio 2019 : Build Problems</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-std-toupper-—-gt-toupper"><a href="#1-std-toupper-—-gt-toupper" class="headerlink" title="1. std::toupper —&gt; ::toupper"></a>1. std::toupper —&gt; ::toupper</h2><h4 id="Original-Code-It’s-OKay-in-VS2017"><a href="#Original-Code-It’s-OKay-in-VS2017" class="headerlink" title="Original Code (It’s OKay in VS2017) :"></a>Original Code (It’s OKay in VS2017) :</h4><p><img src="http://www.qinuu.com/wp-content/uploads/2019/04/VS2019_toupper_1.png">      </p>
<h4 id="VS-Upgraded"><a href="#VS-Upgraded" class="headerlink" title="VS Upgraded :"></a>VS Upgraded :</h4><p><img src="http://www.qinuu.com/wp-content/uploads/2019/04/VS2019_toupper_2.png">  </p>
<h4 id="Code-Updated-It’s-OKay-in-VS2019"><a href="#Code-Updated-It’s-OKay-in-VS2019" class="headerlink" title="Code Updated (It’s OKay in VS2019) :"></a>Code Updated (It’s OKay in VS2019) :</h4><p><img src="http://www.qinuu.com/wp-content/uploads/2019/04/VS2019_toupper_OK.png"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/04/upgrade-to-visual-studio-2019-build-problems/" data-id="cl56gcw1p00x6lgch7cyd1l1w" data-title="Upgrade to Visual Studio 2019 : Build Problems" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-14-dimensionality-reduction" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/03/14-dimensionality-reduction/" class="article-date">
  <time class="dt-published" datetime="2019-04-03T08:33:22.000Z" itemprop="datePublished">2019-04-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>►<a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>►<a class="article-category-link" href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/">Machine Learning Offered By Stanford University</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/04/03/14-dimensionality-reduction/">14 Dimensionality Reduction</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Motivation-I-Data-Compression"><a href="#Motivation-I-Data-Compression" class="headerlink" title="Motivation I Data Compression"></a>Motivation I Data Compression</h2><ol>
<li>compress the data, use up less computer memory or disk space</li>
<li>speed up our learning algorithms.</li>
</ol>
<h2 id="Motivation-II-Visualization"><a href="#Motivation-II-Visualization" class="headerlink" title="Motivation II Visualization"></a>Motivation II Visualization</h2><p>If you have 50 features, it’s very difficult to plot 50-dimensional data. But if you reduce dimensions, the problems is what these new features means.</p>
<h2 id="Principal-Component-Analysis-Problem-Formulation"><a href="#Principal-Component-Analysis-Problem-Formulation" class="headerlink" title="Principal Component Analysis Problem Formulation"></a>Principal Component Analysis Problem Formulation</h2><p>By far the most commonly used algorithm is something called principal components analysis or PCA. What PCA does is it tries to find the surface onto which to project the data so as to minimize that. Before applying PCA it’s standard practice to first perform mean normalization and feature scaling.</p>
<h2 id="Principal-Component-Analysis-Algorithm"><a href="#Principal-Component-Analysis-Algorithm" class="headerlink" title="Principal Component Analysis Algorithm"></a>Principal Component Analysis Algorithm</h2><p><strong>Reduce the dimensions :</strong></p>
<ol>
<li>Mean normalization, maybe perform feature scaling as well</li>
<li>Covariance matrix, [latex]\sum &#x3D; \frac {1}{m} \sum _{i&#x3D;1}^{n}(x^{(i)})(x^{(i)})^T[&#x2F;latex]</li>
<li>Eigenvectors of the matrix sigma</li>
</ol>
<h2 id="Choosing-The-Number-Of-Principal-Components"><a href="#Choosing-The-Number-Of-Principal-Components" class="headerlink" title="Choosing The Number Of Principal Components"></a>Choosing The Number Of Principal Components</h2><p>The variation of the training sets : [latex]\frac {1}{m} \sum_{i&#x3D;1}^{m} \left \ x^{(i)} \right \^2[&#x2F;latex] Try to choose k, a pretty common rule of thumb for choosing k is to choose the smaller values so that the ratio of  the average square projection error and the total variation in the data between these is less than 0.01. [latex]\frac {\frac {1}{m} \sum_{i&#x3D;1}^{m} \left \ x^{(i)} - x^{(i)}_{approx} \right \^2}{\frac {1}{m} \sum_{i&#x3D;1}^{m} \left \ x^{(i)} \right \ ^2} &#x3D; 1 - \frac {\sum_{i&#x3D;1}^{k}S_{ii}}{\sum_{i&#x3D;1}^{n}S_{ii}} \leq 1 \%[&#x2F;latex]   [latex]\frac {\sum_{i&#x3D;1}^{k}S_{ii}}{\sum_{i&#x3D;1}^{n}S_{ii}} \geq 99 \%[&#x2F;latex]   After compressed :  [latex]x^{(i)}_{approx} &#x3D; U_{reduce}Z^{(i)}[&#x2F;latex]</p>
<h2 id="Advice-for-Applying-PCA"><a href="#Advice-for-Applying-PCA" class="headerlink" title="Advice for Applying PCA"></a>Advice for Applying PCA</h2><ul>
<li>Don’t think of PCA as a way to prevent over-fitting. A much better way to address it, to use regularization. And the reason is that it throws away or reduces the dimension of your data without knowing what the values of y is so that it might throw away some valueable information.</li>
<li>First consider doing it with your original raw data [latex]x^{(i)}[&#x2F;latex], and only if that doesn’t do what you want, then implement PCA before using [latex]Z^{(i)}[&#x2F;latex].</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/04/03/14-dimensionality-reduction/" data-id="cl56gcvtx003mlgchgdsc2cw2" data-title="14 Dimensionality Reduction" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/11/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" href="/page/13/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Cloud-Computing/">Cloud Computing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer Vision</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/">DevOps</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Internet-Of-Things/">Internet Of Things</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Multiple-Programming-Languages/">Multiple Programming Languages</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Operating-System/">Operating System</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wordpress/">Wordpress</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cloud-computing/">cloud-computing</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/cloud-computing/OpenStack-All-In-One/">OpenStack All In One</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cloud-computing/OpenStack-High-Availability/">OpenStack High Availability</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cloud-computing/OpenStack-Pike-Installation/">OpenStack Pike Installation</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cloud-computing/Virtualization/">Virtualization</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/computer-vision/">computer-vision</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/computer-vision/OpenCV/">OpenCV</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/computer-vision/OpenCV/QT/">QT</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/computer-vision/QT/">QT</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep-learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/Deep-Learning-Specialization-Offered-By-deeplearning-ai/">Deep Learning Specialization Offered By deeplearning.ai</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/linux/ARM/">ARM</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/linux/ARM/CentOS-7/">CentOS 7</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/linux/ARM/CentOS-7/Ubuntu-16-04/">Ubuntu 16.04</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/Apache/">Apache</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/CentOS-7/">CentOS 7</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/Ubuntu-16-04/">Ubuntu 16.04</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/X11/">X11</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine-learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/Caffe/">Caffe</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/Deep-Learning/">Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/MXNet/">MXNet</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/Machine-Learning-Offered-By-Stanford-University/">Machine Learning Offered By Stanford University</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/TensorFlow/">TensorFlow</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/Yolo/">Yolo</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/">multiple-programming-languages</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Assembly/">Assembly</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Boost/">Boost</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/C/">C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/JavaScript/">JavaScript</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Lua/">Lua</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/OpenSSL/">OpenSSL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Rust/">Rust</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/multiple-programming-languages/Web-Service/">Web Service</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/">operating-system</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/Android/">Android</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/Android/Linux/">Linux</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/Linux/">Linux</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/Linux/Windows/">Windows</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/MacOS/">MacOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/OpenHarmony/">OpenHarmony</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/operating-system/Windows/">Windows</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/the-internet-of-thingslot/">the-internet-of-thingslot</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/the-internet-of-thingslot/i-MX-6ULL/">i.MX 6ULL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/the-internet-of-thingslot/i-MX-RT/">i.MX RT</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/uncategorized/">uncategorized</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/windows/">windows</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/windows/Android-Studio/">Android Studio</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/windows/Android-Studio/GDA/">GDA</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/windows/Android-Studio/GDA/JEB/">JEB</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/windows/IDA-Pro/">IDA Pro</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/windows/Visual-Studio/">Visual Studio</a></li></ul></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/07/04/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2021/09/10/i-mx6ull-linux-%E9%A9%B1%E5%8A%A8%E7%AF%87/">I.MX6ULL Linux 驱动篇</a>
          </li>
        
          <li>
            <a href="/2021/09/10/i-mx6ull-linux-%E7%B3%BB%E7%BB%9F%E7%AF%87/">I.MX6ULL Linux 系统篇</a>
          </li>
        
          <li>
            <a href="/2021/09/10/i-mx6ull-linux-%E8%A3%B8%E6%9C%BA%E7%AF%87/">I.MX6ULL Linux 裸机篇</a>
          </li>
        
          <li>
            <a href="/2021/09/10/i-mx6ull-linux-%E5%85%A5%E9%97%A8%E7%AF%87/">I.MX6ULL Linux 入门篇</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>